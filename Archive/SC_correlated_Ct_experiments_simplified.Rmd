---
title: "Correlated Ct Data Experiments"
author: "Claire Donnat, Saskia Comess"
date: "December 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(fitdistrplus)
library(DescTools)
library(data.table)
library(dplyr)
```

# Load the real data and extract the distribution parameters
```{r loading}
# Get all tests
tests <- data.table::fread("alltests_1mar24jun_v1.csv")

# Keep only valid positive ct values for first tests
tests %>% filter(result == "positive", firsttest==TRUE,!is.na(cttarget)) %>% pull(cttarget) -> cts

# Fit distribution
# Plot distribution and skew/kurtosis of ct values of real first tests
plotdist(cts, histo = TRUE, demp = TRUE, breaks=18)
descdist(cts, boot = 1000)

# Fit distributions
fw <- fitdist(cts, "weibull")
fno <- fitdist(cts, "norm")
fg <- fitdist(cts, "gamma")
fln <- fitdist(cts, "lnorm")

# Plot fit distributions and generate goodness-of-fit statistics
par(mfrow = c(2, 2))
plot.legend <- c("weibull","normal","gamma", "lnorm")
denscomp(list(fw,fno,fg,fln), legendtext = plot.legend,xlim=c(0,50))
qqcomp(list(fw,fno,fg,fln), legendtext = plot.legend)
cdfcomp(list(fw,fno,fg,fln), legendtext = plot.legend)
ppcomp(list(fw,fno,fg,fln), legendtext = plot.legend)
gofstat(list(fw,fno,fg,fln))

```

Weibull has best fit. Extract fit parameters. We can thus assume that the Ct values are sampled from a Weibull distribution with shape 4.55 and scale 29.86.
```{r get_best_fit}
summary(fw)
shape_w = summary(fw)[[1]][1]
scale_w = summary(fw)[[1]][2]
```

# Generate un-correlated Ct data
The viral load distribution changes from population to population. As such, we need to take this variability into account: we consider as a surrogate for this variability the proportion of variables that are above the Limit of Detection.

To achieve this, we simply jiggle the distribution:
- Step 1: we sample 50,000 samples from our fitted Weibul distribution
- Step 2: for a fixed lod = 35, we create a dictionary between the jiggling and the quantile associated to 35.
- Step 3: we create a second dictionary mapping the percentage above the threshold and the correct jiggling.

```{r}
## GENERATE UN-CORRELATED Ct DATA
# Add variable of proportion Ct value >LoD to model, as surrogate for differences in viral load distribution in different populations

# Number of replicates to generate ecdf offset values for above.
set.seed(42)
# x<-50000
x<-5000

# Determine ct value quantiles for real first tests vs. fitted Weibull distribution
quantile(cts,c(0.5,0.25,0.75,0.95,0.99))
quantile(fw,c(0.5,0.25,0.75,0.95,0.99))

# Create simulated vector of ct values with same shape as that from Weibull distribution fit to ct values from real first tests
# 5000 draws from weibull with shape and scale parameters drawn from real data
ct_fake_input <- rweibull(x,fw[[1]][1],fw[[1]][2]) 

# Create matrix of desired input parameters
# Change above.lod to % samples with ct value >LoD to reflect actual population of interest. Changing "lod" itself has no effect on model output.
lod <- 35
above.lod <- seq(0.05,0.3,0.05)
translation_vector <- seq(-10,15,0.01)
mat<-matrix(ncol=3,nrow=length(translation_vector))

# Loop 1: fix LOD; for known shift, what percent of samples are above LoD (a)? 
for(v in 1:length(translation_vector)){
  i=1 
  fn<-ecdf(subset(pmax(5,ct_fake_input+translation_vector[v]),
                  (pmax(5,ct_fake_input+translation_vector[v]))<45)) ## selects adequate values within the sample
			a<-1-fn(lod) ## percent of cvalues in the distribution above the LoD 
			mat[(v-1)+i,1]<-lod
			mat[(v-1)+i,2]<-a
			mat[(v-1)+i,3]<-translation_vector[v]
}

# Shift ct values for each LoD and %above lod
mat2<-matrix(ncol=3,nrow=length(above.lod))

# Loop 2: fix LOD; for known a, how much should you shift? 
for(j in 1:length(above.lod)){
	tmp<-subset(mat,mat[,1]==lod)
	u<-tmp[which.min(abs(above.lod[j]-tmp[,2])),3]
	mat2[j,1]<-lod[i]
	mat2[j,2]<-above.lod[j]
	mat2[j,3]<-u
}
```

# Generate correlated Ct data
```{r}
## GENERATE CORRELATED Ct DATA
source("generating_correlated_data.R") # contains fxn create_correlated_Cts

# Create simulated vector of ct values with same shape as that from Weibull distribution fit to ct values from real first tests
###  Create fake correlated Cts
G <-  4 # group size
N <-  x
# creating a single group of correlated data from Weibull dist
ct_fake_input_corr <- data.frame("Ct" = create_correlated_Cts(type="block", N=G, rho=0.8),
                            "Z" = rep(1,G))
# creating 50000 data points, in correlated groups of size G
# 50,000 data points total, groups of size 4 (12,500 groups)
for (i in 2:(N/G)){ # N%/%G? 
  ct_fake_input_corr <- rbind(ct_fake_input_corr,
                         data.frame("Ct" =create_correlated_Cts(type="block", N=G, rho=0.8),
                                     "Z" = rep(i,G))
  )
}

```

# Include the probit  coefficients
The probits scores are necessary to compute the viral load.
```{r}
# probit data input
probit_input <- read.csv("probit_zscores_cts_tissue_agnostic.csv")
probit_t<-subset(probit_input,probit_input$z_value<=1.96 & probit_input$z_value>=-1.96)
probit<-probit_t[,c(2,4,3)]
probit<-probit[order(probit$z_value,probit$ct_value),]
z_scores<-as.numeric(unlist(distinct(probit,z_value)))

# Number of replicates for model
set.seed(42)
n <- 10000

pool.max<-20
probit.mode<-c("base","dsa.lower","dsa.upper","psa") 
probit.mode.index<-1 # 1 = no variation, 2, = LLN, 3 = ULN, 4 = probabilistic
probit.z.indices<-c(488,1,length(z_scores)) # 488 is a z score of 0 (base case) in the z index vector
dilution.vary.index<-1 # 1 = no variation, 2 = probabilistic
```

# Loops to vary % above each LOD for different combinations of pool size, prevalence, and positives
## experiment_loop: Correlated Individuals
experiment_loop() calculates the weighted means using null probabilities (assuming no correlation between individuals, binomial distribution) and using simulated probabilities (accounting for correlated individuals, probability of transmission within network specified by min, max in the calc_probs() fxn) 
```{r correlated_individuals}
## NAIVE Loop - sampling data uniformly at random
# Model loop, vary % above each LOD (simplified from original code)
source("MCMC_sim.R") # contains calc_probs() fxn
pool.max = 20

experiment_loop <- function(above, ct_dat, sim_min, sim_max){
  ct_set <- pmax(5,subset(ct_dat + mat2[above,3], ct_dat + mat2[above,3]<45)) 
  # (1) generate additional set of C_t values with above = 5-30% of values above each LoD; subset to only valid Ct values (<45)
  # (2) ct_set is the parallel maximum of the C_t values from (1) vs. 5 (why 5??)
  threshold.ct <- c(sample(ct_set, n, replace=T)) # sample ct_set with replacement
  
  rbindlist(lapply(1:pool.max, function (p) { # pool size
    rbindlist(lapply(c(0.001,0.01,0.05,0.1, 0.15), function(prevalence) { # prevalence ("proportion positive tests")
      # 0.001,0.01,0.05,0.1, 0.15
      sim_probs <- calc_probs(p, prevalence, min=sim_min, max=sim_max, B=1000)
      # specify range of correlation to sample from (min, max)
      rbindlist(lapply(0:p, function(positives) { # number of positives
        
        if (positives == 0) {
          data.frame(limit=lod, pool=p, pos=positives, prevalence=prevalence, 
                     above.llod = above.lod[above], 
                     concentration=0, 
                     probability = sim_probs[which(sim_probs$n == 0), "Freq"],
                     probability_null = dbinom(positives, p, prevalence), 
                     random=0, z.index=0,
                     call.each.conc=FALSE, tests=1, tn=1,tp=0,fn=0,fp=0)
        } 
        else {
          dat <- matrix(sample(threshold.ct, positives * n, replace=T), nrow=positives) 
          # sample data uniformly at random 
          # n samples of positives, rearrange into a matrix of positive rows, n columns
          
          each.conc = -log2(colSums(2^-dat)/p)+ifelse(dilution.vary.index==1,0,rnorm(mean=0,sd=1.1,n=ncol(dat))) 
          # sd of 1.1 reflects confidence interval for deviation from perfect log2 dilution in assays
          # calculation dilution based on number of positives (colSum) in total pool size (p)
          
          data.frame(
            limit=lod,
            pool=p,
            pos=positives,
            prevalence=prevalence,
            above.llod=above.lod[above],
            concentration=each.conc,
            # probability = dbinom(positives, p, prevalence)/n,
            probability = sim_probs[which(sim_probs$n == positives), "Freq"]/n,
            probability_null = dbinom(positives, p, prevalence)/n,
            random=sample(n,n,replace = TRUE)/n, #
            z.index=ifelse(probit.mode.index<4,probit.z.indices[probit.mode.index],
                           sample(1:length(z_scores),n,replace=T))) %>%
            mutate(
              call.each.conc=probit[1+(z.index-1)*571+each.conc*10-(lod-35.9)*10,2]>random,
              tests=1 + p * (call.each.conc), # number of tests done (number positive pools + pool size)
              tn=0,
              tp=1 * (call.each.conc),
              fn=1 * (!call.each.conc),
              fp=0)
        }
      }))
    }))
  }))
}

# apply the model loop to the fake correlated data
allfirst.poolct <- rbindlist(lapply(1:length(above.lod), experiment_loop, sim_min = 0.4, sim_max = 0.6, ct_dat = ct_fake_input))

group_by(allfirst.poolct, pool, prevalence, above.llod, limit) %>% 
  summarize(pos1=weighted.mean(pos, w=probability),
            pos_null=weighted.mean(pos, w=probability_null),
            total.tests=weighted.mean(tests, w=probability), 
            total.tests_null=weighted.mean(tests, w=probability_null), 
            tests.per.sample=weighted.mean(tests, w=probability)/mean(pool), # calculate tests per sample
            tests.per.sample_null=weighted.mean(tests, w=probability_null)/mean(pool),
            tn1=weighted.mean(tn, w=probability), 
            tp1=weighted.mean(tp, w=probability), 
            fn1=weighted.mean(fn, w=probability), 
            fp1=weighted.mean(fp, w=probability),
            ppa = weighted.mean(tp/(fn + tp), w=probability, na.rm = TRUE),
            ppa_null = weighted.mean(tp/(fn + tp), w=probability_null, na.rm = TRUE),
            tn_null=weighted.mean(tn, w=probability_null), 
            tp_null=weighted.mean(tp, w=probability_null), 
            fn_null=weighted.mean(fn, w=probability_null), 
            fp_null=weighted.mean(fp, w=probability_null)) -> apw
# rm(allfirst.poolct)

all <- as.data.frame(apw)
# rm(apw)

#all2 <- all %>% mutate(ppa=tp/(tp+fn))
#cpi <- as_tibble(BinomCI(all2$ppa*n,n,conf.level=0.95,method="clopper-pearson"))
#allci <- bind_cols(all2,cpi)

cpi <- as_tibble(BinomCI(all$ppa*n,n,conf.level=0.95,method="clopper-pearson"))
allci <- bind_cols(all,cpi)

# write.csv(allci,"correlated_individuals_rho.1.2.csv")
write.csv(allci,"correlated_individuals_rho.4.6.csv")

#correlated_individuals_rho.1.2, calc_probs(p, prevalence, min=0.1, max=0.2, B=1000)
```

```{r}
# quick check: should have same results for null and alternative when pool size is 1
allci %>%
  filter(pool == 1) %>%
  dplyr::select(ppa, ppa_null)
```
Rho = (0.1, 0.2)
```{r}
corr_indiv_.1.2 <- read.csv("correlated_individuals_rho.1.2.csv")
corr_indiv_.1.2_null <- corr_indiv_.1.2
corr_indiv_.1.2$null <- "Correlated"
corr_indiv_.1.2_null$null <- "Uncorrelated"

pdf("plot.ppa.corrindiv.pdf",width=8, height=5)  
ggplot() +
  geom_line(corr_indiv_.1.2, mapping = aes(x=pool, y= ppa, color=as.factor(prevalence), linetype = null)) +
  # y= tp1/(tp1 + fn1)
  geom_line(corr_indiv_.1.2_null, mapping = aes(x=pool, y=ppa_null, color=as.factor(prevalence), linetype = null)) +
  # y=tp_null/(tp_null + fn_null)
  facet_wrap(vars(factor(corr_indiv_.1.2$above.llod, labels=c("5% samples Ct>LoD","10% samples Ct>LoD","15% samples Ct>LoD","20% samples Ct>LoD","25% samples Ct>LoD","30% samples Ct>LoD")))) +
  theme_bw() + 
  scale_color_brewer(palette="RdYlBu", name="Prevalence") + 
  xlab("Pool size") + ylab("Expected positive percent agreement") +
  ggtitle("Correlated Individuals (rho = 0.1 - 0.2) vs. Uncorrelated") +
  scale_x_continuous(limits=c(1,20), breaks=seq(0,20,2)) + scale_y_continuous(limits=c(0.5,1),breaks=seq(0.5,1,.1)) +
  guides(color=guide_legend(title="Proportion of\ntests positive")) + 
  guides(linetype=guide_legend(title="Correlation Structure")) 
dev.off()

# Print plot of pool size vs. average tests/sample, panel grid of %Ct > LoD, color by proportion test pos
pdf("plot.eff.corrindiv.pdf",width=8, height=5)  
ggplot() +
  geom_line(corr_indiv_.1.2, mapping = aes(x=pool, y= tests.per.sample, color=as.factor(prevalence), linetype = null)) +
  geom_line(corr_indiv_.1.2_null, mapping = aes(x=pool, y= tests.per.sample_null, color=as.factor(prevalence), linetype = null)) +
  facet_wrap(vars(factor(corr_indiv_.1.2$above.llod, labels=c("5% samples Ct>LoD","10% samples Ct>LoD","15% samples Ct>LoD","20% samples Ct>LoD","25% samples Ct>LoD","30% samples Ct>LoD")))) +
  theme_bw() + 
  scale_color_brewer(palette="RdYlBu", name="Prevalence") + 
  xlab("Pool size") + ylab("Average tests per sample") +
  ggtitle("Correlated Individuals (rho = 0.1 - 0.2) vs. Uncorrelated") +
  scale_x_continuous(limits=c(1,20), breaks=seq(0,20,2)) + scale_y_continuous(trans="reverse", limits=c(1.2,0),breaks=seq(0,1.2,0.2)) +
  guides(color=guide_legend(title="Proportion of\ntests positive")) + 
  guides(linetype=guide_legend(title="Correlation Structure")) 
dev.off()

```

Rho = (0.4, 0.6)
```{r}
corr_indiv_.4.6 <- read.csv("correlated_individuals_rho.4.6.csv")
corr_indiv_.4.6_null <- corr_indiv_.4.6
corr_indiv_.4.6$null <- "Correlated"
corr_indiv_.4.6_null$null <- "Uncorrelated"

pdf("plot.ppa.corrindiv.4.6.pdf",width=8, height=5)  
ggplot() +
  geom_line(corr_indiv_.4.6, mapping = aes(x=pool, y= ppa, color=as.factor(prevalence), linetype = null)) +
  geom_line(corr_indiv_.4.6_null, mapping = aes(x=pool, y=ppa_null, color=as.factor(prevalence), linetype = null)) +
  facet_wrap(vars(factor(corr_indiv_.4.6$above.llod, labels=c("5% samples Ct>LoD","10% samples Ct>LoD","15% samples Ct>LoD","20% samples Ct>LoD","25% samples Ct>LoD","30% samples Ct>LoD")))) +
  theme_bw() + 
  scale_color_brewer(palette="RdYlBu", name="Prevalence") + 
  xlab("Pool size") + ylab("Expected positive percent agreement") +
  ggtitle("Correlated Individuals (rho = 0.4 - 0.6) vs. Uncorrelated") +
  scale_x_continuous(limits=c(1,20), breaks=seq(0,20,2)) + scale_y_continuous(limits=c(0.5,1),breaks=seq(0.5,1,.1)) +
  guides(color=guide_legend(title="Proportion of\ntests positive")) + 
  guides(linetype=guide_legend(title="Correlation Structure")) 
dev.off()

# Print plot of pool size vs. average tests/sample, panel grid of %Ct > LoD, color by proportion test pos
pdf("plot.eff.corrindiv.4.6.pdf",width=8, height=5)  
ggplot() +
  geom_line(corr_indiv_.4.6, mapping = aes(x=pool, y= tests.per.sample, color=as.factor(prevalence), linetype = null)) +
  geom_line(corr_indiv_.4.6_null, mapping = aes(x=pool, y= tests.per.sample_null, color=as.factor(prevalence), linetype = null)) +
  facet_wrap(vars(factor(corr_indiv_.4.6$above.llod, labels=c("5% samples Ct>LoD","10% samples Ct>LoD","15% samples Ct>LoD","20% samples Ct>LoD","25% samples Ct>LoD","30% samples Ct>LoD")))) +
  theme_bw() + 
  scale_color_brewer(palette="RdYlBu", name="Prevalence") + 
  xlab("Pool size") + ylab("Average tests per sample") +
  ggtitle("Correlated Individuals (rho = 0.4 - 0.6) vs. Uncorrelated") +
  scale_x_continuous(limits=c(1,20), breaks=seq(0,20,2)) + scale_y_continuous(trans="reverse", limits=c(1.2,0),breaks=seq(0,1.2,0.2)) +
  guides(color=guide_legend(title="Proportion of\ntests positive")) + 
  guides(linetype=guide_legend(title="Correlation Structure")) 
dev.off()

```

## Correlated INDIVIDUALS loop
### sampling data without accounting for correlation structure, weighting by the simulated probability of k positives given group size, prevalence
```{r probit_model}
# sim_probs_house <- read.csv("sim_probs_house.csv")
# sim_probs_house[,1] <- NULL
# rows = total number of infections (1: (group size)), columns = group size
sim_probs_.1.2 <- read.csv("sim_probs_.1.2.csv")
sim_probs_.1.2[,1] <- NULL

## NAIVE Loop - sampling data uniformly at random
# Model loop, vary % above each LOD (simplified from original code)
experiment_loop_depr<- function(above, ct_dat, sim_probs){
  ct_set <- pmax(5,subset(ct_dat + mat2[above,3], ct_dat + mat2[above,3]<45)) 
  # (1) generate additional set of C_t values with 5-30% of values above each LoD; subset to only valid Ct values (<45)
  # (2) ct_set is the parallel maximum of the C_t values from (1) vs. 5 (why 5??)
  threshold.ct <- c(sample(ct_set, n, replace=T)) # why do we sample ct_set with replacement? doesn't this create correlation?
  
  rbindlist(lapply(2:pool.max, function (p) { # pool size
    rbindlist(lapply(c(0.001,0.01,0.03,0.05,0.1), function(prevalence) { # proportion positive tests 
      rbindlist(lapply(0:p, function(positives) { # number of positives
        
        if (positives == 0) {
          data.frame(limit=lod, pool=p, pos=positives, prevalence=prevalence, 
                     above.llod = above.lod[above], 
                     concentration=0, 
                     probability = (1-prevalence)^p, 
                     random=0, z.index=0,
                     call.each.conc=FALSE, tests=1, tn=1,tp=0,fn=0,fp=0)
        } 
        else {
          dat <- matrix(sample(threshold.ct, positives * n, replace=T), nrow=positives) 
          # sample data uniformly at random 
          # n samples of positives, rearrange into a matrix of positive rows, n columns
          
          each.conc = -log2(colSums(2^-dat)/p)+ifelse(dilution.vary.index==1,0,rnorm(mean=0,sd=1.1,n=ncol(dat))) 
          # sd of 1.1 reflects confidence interval for deviation from perfect log2 dilution in assays
          # calculation diluation based on number of positives (colSum) in total pool size (p)
          
          data.frame(
            limit=lod,
            pool=p,
            pos=positives,
            prevalence=prevalence,
            above.llod=above.lod[above],
            concentration=each.conc,
            # probability = dbinom(positives, p, prevalence)/n,
            probability = (1-(1-prevalence)^p)*sim_probs[positives, (p-1)],
            # rows = total number of infections (1: (group size)), columns = group size
            random=sample(n,n,replace = TRUE)/n, #
            z.index=ifelse(probit.mode.index<4,probit.z.indices[probit.mode.index],
                           sample(1:length(z_scores),n,replace=T))) %>%
            mutate(
              call.each.conc=probit[1+(z.index-1)*571+each.conc*10-(lod-35.9)*10,2]>random,
              tests=1 + p * (call.each.conc), # number of tests done (number positive pools + pool size)
              tn=0,
              tp=1 * (call.each.conc),
              fn=1 * (!call.each.conc),
              fp=0)
        }
      }))
    }))
  }))
}

# apply the model loop to the fake correlated data
allfirst.poolct <- rbindlist(lapply(1, experiment_loop, ct_dat = ct_fake_input, sim_probs = sim_probs_.1.2))

group_by(allfirst.poolct, pool, prevalence, above.llod, limit) %>% 
  summarize(pos=weighted.mean(pos, w=probability),
            total.tests=weighted.mean(tests, w=probability), 
            tests.per.sample=weighted.mean(tests, w=probability)/mean(pool), # calculate tests per sample
            tn=weighted.mean(tn, w=probability), 
            tp=weighted.mean(tp, w=probability), 
            fn=weighted.mean(fn, w=probability), 
            fp=weighted.mean(fp, w=probability)) -> apw

rm(allfirst.poolct)

all <- as.data.frame(apw)
rm(apw)

all2 <- all %>%
  mutate(ppa=tp/(tp+fn))
cpi <- as_tibble(BinomCI(all2$ppa*n,n,conf.level=0.95,method="clopper-pearson"))
allci <- bind_cols(all2,cpi)

write.csv(allci,"model_output_corr_indiv_.1.2.csv")
```
```{r}
ggplot(apw, aes(x=pool, y=tp/(tp + fn), color=as.factor(prevalence))) + 
  geom_line() +
  facet_wrap(vars(factor(above.llod, labels=c("5% samples Ct>LoD","10% samples Ct>LoD","15% samples Ct>LoD","20% samples Ct>LoD","25% samples Ct>LoD","30% samples Ct>LoD")))) +
  theme_bw() + 
  scale_color_brewer(palette="RdYlBu", name="Prevalence") + 
  xlab("Pool size") + ylab("Expected positive percent agreement") +
  scale_x_continuous(limits=c(1,20), breaks=seq(0,20,2)) + #scale_y_continuous(limits=c(0.9,1),breaks=seq(0.9,1,.01)) +
  scale_y_log10() + 
  guides(color=guide_legend(title="Proportion of\ntests positive"))
```



## Correlated Ct loop - sampling data accounting for correlation structure of data
```{r}
# MODIFIED Loop for Correlated Data 
# Model loop, vary % above each LOD
# experiment_loop_corr takes entire ct_dat data frame as argument- should have columns Ct and Z
# ct_dat <- ct_fake_input_corr
# above <- 1
experiment_loop_corr <- function(above, ct_dat){ 
  ct_dat$Ct <- ct_dat$Ct + mat2[above,3] # shift the Ct values by specified percent
  ct_set <- subset(ct_dat, ct_dat$Ct<45) # subset to valid Ct values
  relevant_groups = unlist(unique(ct_set %>% group_by(Z) %>% tally() %>% filter(n==G) %>% dplyr::select(Z)))
  ct_set = ct_set[which(ct_set$Z %in% relevant_groups),]
  threshold.ct_index <- unlist(sapply(sample(ct_set$Z, (n/G), replace = TRUE), function(x) {which(ct_set$Z == x)})) 
  # sample the indexes by group (i.e. always select all 4 members if a given group is sampled)
  threshold.ct <- data.frame(Ct = ct_set$Ct[threshold.ct_index], Z = rep(1:(n/G), each = G)) 
  # replicate Ct values by number of times they appear in sampled indexes (number of times that group was sampled)
  
  rbindlist(lapply(2:pool.max, function (p) { # pool size
    rbindlist(lapply(c(0.001,0.01,0.03,0.05,0.1,0.15), function(prevalence) { # proportion positive tests 
      rbindlist(lapply(2:p, function(positives) { # number of positives
        # rbindlist(lapply(c(0.5, 0.75, 1), function(group_frac) {
          
          if (positives == 0) {
            data.frame(limit=lod, pool=p, pos=positives, prevalence=prevalence, 
                       above.llod = above.lod[above], 
                       concentration=0, probability = dbinom(positives, p, prevalence), random=0, z.index=0,
                       call.each.conc=FALSE, tests=1, tn=1,tp=0,fn=0,fp=0)
          } 
          else {
            # two step sampling for creating positives
            ## 1. Sample fraction of group that is correlated
            group_frac <- 1 # fraction of each group to sample
            frac_pos <- round(G*group_frac, digits = 0) 
            
            t <- sapply(sample(threshold.ct$Z, n, replace = T), function(x) return(threshold.ct$Ct[which(threshold.ct$Z == x)[1:min(frac_pos, positives)]])) # for each experiment (1:n), sample frac_pos number of individuals from each group
            
            t_dat <- as.matrix(t, ncol = n, nrow = min(frac_pos, positives))
            print(c(dim(t_dat), positives, p))
            
            ## 2. sample remaining individuals independently (to complete number of positives in pool)
            if (positives - min(frac_pos, positives) > 0){
              l <- matrix(sample(threshold.ct$Ct, (positives - min(frac_pos, positives))*n, replace=T), ncol = n)
              print(paste("dim l", dim(l)))
              tl_dat <- rbind(t_dat, l) # combine correlated and uncorrelated into single data frame
            }
            else {
              tl_dat <- t_dat
            }
            
            dat <- tl_dat # each column is an experiment, each entry in a row is a sample
            print(paste("dim dat", dim(dat)))
            
            each.conc = -log2(colSums(2^-dat)/p)+ifelse(dilution.vary.index==1,0,rnorm(mean=0,sd=1.1,n=ncol(dat)))
            head(each.conc)
            print(length(each.conc)) 
            # sum over each column; negatives dilute the sample, calculate the dilution
            # sd of 1.1 reflects confidence interval for deviation from perfect log2 dilution in assays
            
            data.frame(
              limit=lod,
              pool=p,
              pos=positives,
              prevalence=prevalence,
              group_frac = group_frac,
              above.llod=above.lod[above],
              concentration=each.conc,
              probability = dbinom(positives, p, prevalence)/n,
              # probability of seeing this many positives in a pool of size p with given population prevalence
              random=sample(n,n,replace = TRUE)/n, #
              z.index=ifelse(probit.mode.index<4,probit.z.indices[probit.mode.index],
                             sample(1:length(z_scores),n,replace=T))) %>%
              mutate(
                call.each.conc=probit[1+(z.index-1)*571+each.conc*10-(lod-35.9)*10,2]>random,
                tests=1 + p * (call.each.conc), # number of tests done (number positive pools + pool size)
                tn=0,
                tp=1 * (call.each.conc),
                fn=1 * (!call.each.conc),
                fp=0)
          }
        #}))
      }))
    }))
  }))
}

start_time <- Sys.time()
allfirst.poolct <- rbindlist(experiment_loop_corr, ct_dat = ct_fake_input_corr)
end_time <- Sys.time()
end_time-start_time

# TODO: 
# they do expectation of the ratios; we want ratio of the expectations
# allfirst.poolct = allfist.poolct %>% mutate(ratio = tp/tp+fn) 
# add ratio to group_by function

group_by(allfirst.poolct, pool, prevalence, above.llod, limit) %>% 
  summarize(pos=weighted.mean(pos, w=probability), 
            # computing expected number of positives 
            # weighted mean of the positives based on probability 
            total.tests=weighted.mean(tests, w=probability), 
            tests.per.sample=weighted.mean(tests, w=probability)/mean(pool), # calculate tests per sample
            tn=weighted.mean(tn, w=probability), 
            tp=weighted.mean(tp, w=probability), 
            # expectation of true positives: number of true positives observed in simulation, weighted by how likely that was to occur given prevalence 
            fn=weighted.mean(fn, w=probability), 
            fp=weighted.mean(fp, w=probability)) -> apw

rm(allfirst.poolct)

all <- as.data.frame(apw)
rm(apw)

all2 <- all %>%
  mutate(ppa=tp/(tp+fn))
cpi <- as_tibble(BinomCI(all2$ppa*n,n,conf.level=0.95,method="clopper-pearson"))
allci <- bind_cols(all2,cpi)

write.csv(allci,"model_output_corr_groupfrac_1.csv")
# write.csv(allci,"model_output_corr_groupfrac_34.csv")
# write.csv(allci,"model_output_corr_groupfrac_12.csv")
```



## Plots 

```{r}
allci_corr <- read.csv("model_output_corr.csv") # correlated sampled uniformly (naive loop)
allci_uncorr <- read.csv("model_output.csv")
# allci_corr_group <- read.csv("model_output_corr_grouped.csv")
allci_corr_group1 <- read.csv("model_output_corr_groupfrac_1.csv")
allci_corr_group34 <- read.csv("model_output_corr_groupfrac_34.csv")
allci_corr_group12 <- read.csv("model_output_corr_groupfrac_12.csv")
allci_corr_indiv <- read.csv("model_output_corr_individ.csv")
allci_corr_indiv_12 <- read.csv("model_output_corr_indiv_.1.2.csv")
test <- read.csv("test.csv")
```

```{r}
ggplot(apw, aes(x=pool, y=tp/(tp + fn), color=as.factor(prevalence))) + 
  geom_line() +
  facet_wrap(vars(factor(above.llod, labels=c("5% samples Ct>LoD","10% samples Ct>LoD","15% samples Ct>LoD","20% samples Ct>LoD","25% samples Ct>LoD","30% samples Ct>LoD")))) +
  theme_bw() + 
  scale_color_brewer(palette="RdYlBu", name="Prevalence") + 
  xlab("Pool size") + ylab("Expected positive percent agreement") +
  scale_x_continuous(limits=c(1,20), breaks=seq(0,20,2)) + #scale_y_continuous(limits=c(0.9,1),breaks=seq(0.9,1,.01)) +
  scale_y_log10() + 
  guides(color=guide_legend(title="Proportion of\ntests positive"))
```


```{r}
ggplot(allci, aes(x=pool, y=tp/(tp + fn), color=as.factor(prevalence))) + 
  geom_line() +
  facet_wrap(vars(factor(above.llod, labels=c("5% samples Ct>LoD","10% samples Ct>LoD","15% samples Ct>LoD","20% samples Ct>LoD","25% samples Ct>LoD","30% samples Ct>LoD")))) +
  theme_bw() + 
  scale_color_brewer(palette="RdYlBu", name="Prevalence") + 
  xlab("Pool size") + ylab("Expected positive percent agreement") +
  scale_x_continuous(limits=c(1,20), breaks=seq(0,20,2)) + scale_y_continuous(limits=c(0.5,1),breaks=seq(0.5,1,.1)) +
  guides(color=guide_legend(title="Proportion of\ntests positive"))
```

### Individual Plots
```{r generate_plots, eval=FALSE}
# Generate individual plots

# Print plot of pool size vs. PPA, panel grid of % samples with Ct > LoD, color by proportion test pos
pdf("plot.ppa.above.colprev.pdf",width=8, height=5)
ggplot(allci, aes(x=pool, y=tp/(tp + fn), color=as.factor(prevalence))) + 
  geom_line() +
  facet_wrap(vars(factor(above.llod, labels=c("5% samples Ct>LoD","10% samples Ct>LoD","15% samples Ct>LoD","20% samples Ct>LoD","25% samples Ct>LoD","30% samples Ct>LoD")))) +
  theme_bw() + 
  scale_color_brewer(palette="RdYlBu", name="Prevalence") + 
  xlab("Pool size") + ylab("Expected positive percent agreement") +
  scale_x_continuous(limits=c(1,20), breaks=seq(0,20,2)) + scale_y_continuous(limits=c(0.5,1),breaks=seq(0.5,1,.1)) +
  guides(color=guide_legend(title="Proportion of\ntests positive"))
dev.off()

# Print plot of pool size vs. PPA, panel grid of proportion test pos, color by % samples with Ct > LoD
pdf("plot.ppa.prev.colabove.pdf",width=8, height=5)
ggplot(allci, aes(x=pool, y=tp/(tp + fn), color=as.factor(above.llod))) + 
  geom_line() +
  facet_wrap(vars(factor(prevalence, labels=c("0.1% Tests positive", "1% Tests positive", "3% Tests positive", "5% Tests positive", "10% Tests positive","15% Tests positive")))) +
  theme_bw() + 
  scale_color_brewer(palette="RdYlBu", name="Prevalence") + 
  xlab("Pool size") + ylab("Expected positive percent agreement") +
  scale_x_continuous(limits=c(1,20), breaks=seq(0,20,2)) + scale_y_continuous(limits=c(0.5,1),breaks=seq(0.5,1,.1)) +
  guides(color=guide_legend(title="Proportion\nsamples\nCt > LoD"))
dev.off()

# Print plot of pool size vs. average tests/sample, panel grid of %Ct > LoD, color by proportion test pos
pdf("plot.eff.above.colprev.pdf",width=8, height=5)
ggplot(allci, aes(x=pool, y=tests.per.sample,color=as.factor(prevalence))) + 
  geom_line() +
  facet_wrap(vars(factor(above.llod, labels=c("5% samples Ct>LoD","10% samples Ct>LoD","15% samples Ct>LoD","20% samples Ct>LoD","25% samples Ct>LoD","30% samples Ct>LoD")))) +
  theme_bw() + 
  scale_color_brewer(palette="RdYlBu", name="Prevalence") + 
  xlab("Pool size") + ylab("Average tests per sample") + 
  scale_x_continuous(limits=c(1,20), breaks=seq(0,20,2)) + scale_y_continuous(trans="reverse", limits=c(1.2,0),breaks=seq(0,1.2,0.2)) +
  guides(color=guide_legend(title="Proportion of\ntests positive"))
dev.off()

# Print plot of pool size vs. PPA, gridded showing PPA changes with %>LoD but is constant at different LoDs
# grid <- read.csv("model_output_varylod.varydist.csv")
# grid <- as_tibble(grid)
# pdf("AppendixFigure2.pdf",width=9, height=8)
# ggplot(grid %>% filter((above.llod=="0.05"|above.llod=="0.15"|above.llod=="0.25"),(limit==34|limit==35|limit==36)), aes(x=pool, y=tp/(tp + fn), color=as.factor(prevalence))) + 
#   geom_line() + 
#   facet_grid(rows=vars(factor(limit,levels=c(36,35,34),labels=c("LoD Ct=36","LoD Ct=35","LoD Ct=34"))),cols=vars(factor(above.llod,labels=c("5% Ct>LoD","15% Ct>LoD","25% Ct>LoD")))) + 
#   theme_bw() + 
#   scale_color_brewer(palette="RdYlBu", name="Prevalence") + 
#   xlab("Pool size") + ylab("Expected positive percent agreement") + 
#   scale_x_continuous(limits=c(1,20),breaks=seq(0,20,2)) + scale_y_continuous(limits=c(0.5,1),breaks=seq(0.5,1,.1)) + 
#   guides(color=guide_legend(title="Proportion of\ntests positive"))
# dev.off()

```


### Plots comparing different sampling methods
#### Correlated INDIVIDUALS vs. uncorrelated
```{r}
# correlated (sampled w. grouping) vs. uncorrelated

#subset uncorrelated data to contain same obs as correlated data
# correlated data doesn't have pool size 1
allci_uncorr_sub <- allci_uncorr[allci_uncorr$X %in% allci_corr_indiv$X,]
allci_uncorr_sub$corr_type <- "Uncorrelated"
allci_corr_indiv$corr_type <- "Correlated"

# Print plot of pool size vs. PPA, panel grid of % samples with Ct > LoD, color by proportion test pos
pdf("plot.ppa.above.colprev.corr_indiv.pdf",width=8, height=5)
ggplot() +
  geom_line(allci_corr_indiv, mapping = aes(x=pool, y=tp/(tp + fn), color=as.factor(prevalence), linetype = corr_type)) +
  geom_line(allci_uncorr_sub, mapping = aes(x=pool, y=tp/(tp + fn), color=as.factor(prevalence), linetype = corr_type)) +
  facet_wrap(vars(factor(allci_corr_indiv$above.llod, labels=c("5% samples Ct>LoD","10% samples Ct>LoD","15% samples Ct>LoD","20% samples Ct>LoD","25% samples Ct>LoD","30% samples Ct>LoD")))) +
  theme_bw() + 
  scale_color_brewer(palette="RdYlBu", name="Prevalence") + 
  xlab("Pool size") + ylab("Expected positive percent agreement") +
  ggtitle("Correlated Individuals") +
  scale_x_continuous(limits=c(1,20), breaks=seq(0,20,2)) + scale_y_continuous(limits=c(0.75,1),breaks=seq(0.75,1,.1)) +
  guides(color=guide_legend(title="Proportion of\ntests positive")) + 
  guides(linetype=guide_legend(title="Correlation Structure")) 
dev.off()

# Print plot of pool size vs. PPA, panel grid of proportion test pos, color by % samples with Ct > LoD
pdf("plot.ppa.prev.colabove.groupfrac1.both.pdf",width=8, height=5)
ggplot() + 
  geom_line(allci_corr_group1, mapping = aes(x=pool, y=tp/(tp + fn), color=as.factor(above.llod), linetype = corr_type)) +
  geom_line(allci_uncorr_sub, mapping = aes(x=pool, y=tp/(tp + fn), color=as.factor(above.llod), linetype = corr_type)) +
  facet_wrap(vars(factor(allci_corr_group1$prevalence, labels=c("0.1% Tests positive", "1% Tests positive", "3% Tests positive", "5% Tests positive", "10% Tests positive","15% Tests positive")))) +
  theme_bw() + 
  scale_color_brewer(palette="RdYlBu", name="Prevalence") + 
  xlab("Pool size") + ylab("Expected positive percent agreement") +
  ggtitle("Uncorrelated Data & Correlated Data Sampled by Group (Fraction = 1)") +
  scale_x_continuous(limits=c(1,20), breaks=seq(0,20,2)) + scale_y_continuous(limits=c(0.5,1),breaks=seq(0.5,1,.1)) +
  guides(color=guide_legend(title="Proportion\nsamples\nCt > LoD")) + 
  guides(linetype=guide_legend(title="Correlation Structure")) 
dev.off()

# Print plot of pool size vs. average tests/sample, panel grid of %Ct > LoD, color by proportion test pos
pdf("plot.eff.above.colprev.groupfrac1.both.pdf",width=8, height=5)
ggplot() + 
  geom_line(allci_corr_group1, mapping = aes(x=pool, y=tests.per.sample, color=as.factor(prevalence), linetype = corr_type)) +
  geom_line(allci_uncorr_sub, mapping = aes(x=pool, y=tests.per.sample, color=as.factor(prevalence), linetype = corr_type)) +
  facet_wrap(vars(factor(allci_corr_group1$above.llod, labels=c("5% samples Ct>LoD","10% samples Ct>LoD","15% samples Ct>LoD","20% samples Ct>LoD","25% samples Ct>LoD","30% samples Ct>LoD")))) +
  theme_bw() + 
  scale_color_brewer(palette="RdYlBu", name="Prevalence") + 
  xlab("Pool size") + ylab("Average tests per sample") + 
  ggtitle("Uncorrelated Data & Correlated Data Sampled by Group (Fraction = 1)") +
  scale_x_continuous(limits=c(1,20), breaks=seq(0,20,2)) + scale_y_continuous(limits=c(0, 1.6),breaks=seq(0,1.6,0.2)) +
  guides(color=guide_legend(title="Proportion of\ntests positive")) +
  guides(linetype=guide_legend(title="Correlation Structure"))
dev.off()
```

#### Correlated Ct (sampled uniformly) vs. uncorrelated
```{r}
# Generate Plots with multiple data sets 

# correlated (sampled w.out corr structure) vs. uncorrelated
# Print plot of pool size vs. PPA, panel grid of % samples with Ct > LoD, color by proportion test pos
pdf("plot.ppa.above.colprev.both.pdf",width=8, height=5)
ggplot() +
  geom_line(allci_corr, mapping = aes(x=pool, y=tp/(tp + fn), color=as.factor(prevalence))) +
  geom_line(allci_uncorr, mapping = aes(x=pool, y=tp/(tp + fn), color=as.factor(prevalence)), linetype = "dashed") +
  facet_wrap(vars(factor(allci_corr$above.llod, labels=c("5% samples Ct>LoD","10% samples Ct>LoD","15% samples Ct>LoD","20% samples Ct>LoD","25% samples Ct>LoD","30% samples Ct>LoD")))) +
  theme_bw() + 
  scale_color_brewer(palette="RdYlBu", name="Prevalence") + 
  xlab("Pool size") + ylab("Expected positive percent agreement") +
  scale_x_continuous(limits=c(1,20), breaks=seq(0,20,2)) + scale_y_continuous(limits=c(0.65,1),breaks=seq(0.65,1,.1)) +
  guides(color=guide_legend(title="Proportion of\ntests positive"))
dev.off()

# Print plot of pool size vs. PPA, panel grid of proportion test pos, color by % samples with Ct > LoD
pdf("plot.ppa.prev.colabove.both.pdf",width=8, height=5)
ggplot() + 
  geom_line(allci_corr, mapping = aes(x=pool, y=tp/(tp + fn), color=as.factor(above.llod))) +
  geom_line(allci_uncorr, mapping = aes(x=pool, y=tp/(tp + fn), color=as.factor(above.llod)), linetype = "dashed") +
  facet_wrap(vars(factor(allci_corr$prevalence, labels=c("0.1% Tests positive", "1% Tests positive", "3% Tests positive", "5% Tests positive", "10% Tests positive","15% Tests positive")))) +
  theme_bw() + 
  scale_color_brewer(palette="RdYlBu", name="Prevalence") + 
  xlab("Pool size") + ylab("Expected positive percent agreement") +
  scale_x_continuous(limits=c(1,20), breaks=seq(0,20,2)) + scale_y_continuous(limits=c(0.5,1),breaks=seq(0.5,1,.1)) +
  guides(color=guide_legend(title="Proportion\nsamples\nCt > LoD"))
dev.off()

# Print plot of pool size vs. average tests/sample, panel grid of %Ct > LoD, color by proportion test pos
pdf("plot.eff.above.colprev.both.pdf",width=8, height=5)
ggplot() + 
  geom_line(allci_corr, mapping = aes(x=pool, y=tests.per.sample,color=as.factor(prevalence))) +
  geom_line(allci_uncorr, mapping = aes(x=pool, y=tests.per.sample,color=as.factor(prevalence)), linetype = "dashed") +
  facet_wrap(vars(factor(allci_corr$above.llod, labels=c("5% samples Ct>LoD","10% samples Ct>LoD","15% samples Ct>LoD","20% samples Ct>LoD","25% samples Ct>LoD","30% samples Ct>LoD")))) +
  theme_bw() + 
  scale_color_brewer(palette="RdYlBu", name="Prevalence") + 
  xlab("Pool size") + ylab("Average tests per sample") + 
  scale_x_continuous(limits=c(1,20), breaks=seq(0,20,2)) + scale_y_continuous(trans="reverse", limits=c(1.2,0),breaks=seq(0,1.2,0.2)) +
  guides(color=guide_legend(title="Proportion of\ntests positive"))
dev.off()
```

#### Correlated Ct (sampled w. grouping) vs. Uncorrelated

# group_frac = 1
```{r}
# correlated (sampled w. grouping) vs. uncorrelated

#subset uncorrelated data to contain same obs as correlated data
allci_uncorr_sub <- allci_uncorr[allci_uncorr$X %in% allci_corr_group1$X,]
allci_uncorr_sub$corr_type <- "Uncorrelated"
allci_corr_group1$corr_type <- "Correlated"

# Print plot of pool size vs. PPA, panel grid of % samples with Ct > LoD, color by proportion test pos
pdf("plot.ppa.above.colprev.groupfrac1.both.pdf",width=8, height=5)
ggplot() +
  geom_line(allci_corr_group1, mapping = aes(x=pool, y=tp/(tp + fn), color=as.factor(prevalence), linetype = corr_type)) +
  geom_line(allci_uncorr_sub, mapping = aes(x=pool, y=tp/(tp + fn), color=as.factor(prevalence), linetype = corr_type)) +
  facet_wrap(vars(factor(allci_corr_group1$above.llod, labels=c("5% samples Ct>LoD","10% samples Ct>LoD","15% samples Ct>LoD","20% samples Ct>LoD","25% samples Ct>LoD","30% samples Ct>LoD")))) +
  theme_bw() + 
  scale_color_brewer(palette="RdYlBu", name="Prevalence") + 
  xlab("Pool size") + ylab("Expected positive percent agreement") +
  ggtitle("Uncorrelated Data & Correlated Data Sampled by Group (Fraction = 1)") +
  scale_x_continuous(limits=c(1,20), breaks=seq(0,20,2)) + scale_y_continuous(limits=c(0.65,1),breaks=seq(0.65,1,.1)) +
  guides(color=guide_legend(title="Proportion of\ntests positive")) + 
  guides(linetype=guide_legend(title="Correlation Structure")) 
dev.off()

# Print plot of pool size vs. PPA, panel grid of proportion test pos, color by % samples with Ct > LoD
pdf("plot.ppa.prev.colabove.groupfrac1.both.pdf",width=8, height=5)
ggplot() + 
  geom_line(allci_corr_group1, mapping = aes(x=pool, y=tp/(tp + fn), color=as.factor(above.llod), linetype = corr_type)) +
  geom_line(allci_uncorr_sub, mapping = aes(x=pool, y=tp/(tp + fn), color=as.factor(above.llod), linetype = corr_type)) +
  facet_wrap(vars(factor(allci_corr_group1$prevalence, labels=c("0.1% Tests positive", "1% Tests positive", "3% Tests positive", "5% Tests positive", "10% Tests positive","15% Tests positive")))) +
  theme_bw() + 
  scale_color_brewer(palette="RdYlBu", name="Prevalence") + 
  xlab("Pool size") + ylab("Expected positive percent agreement") +
  ggtitle("Uncorrelated Data & Correlated Data Sampled by Group (Fraction = 1)") +
  scale_x_continuous(limits=c(1,20), breaks=seq(0,20,2)) + scale_y_continuous(limits=c(0.5,1),breaks=seq(0.5,1,.1)) +
  guides(color=guide_legend(title="Proportion\nsamples\nCt > LoD")) + 
  guides(linetype=guide_legend(title="Correlation Structure")) 
dev.off()

# Print plot of pool size vs. average tests/sample, panel grid of %Ct > LoD, color by proportion test pos
pdf("plot.eff.above.colprev.groupfrac1.both.pdf",width=8, height=5)
ggplot() + 
  geom_line(allci_corr_group1, mapping = aes(x=pool, y=tests.per.sample, color=as.factor(prevalence), linetype = corr_type)) +
  geom_line(allci_uncorr_sub, mapping = aes(x=pool, y=tests.per.sample, color=as.factor(prevalence), linetype = corr_type)) +
  facet_wrap(vars(factor(allci_corr_group1$above.llod, labels=c("5% samples Ct>LoD","10% samples Ct>LoD","15% samples Ct>LoD","20% samples Ct>LoD","25% samples Ct>LoD","30% samples Ct>LoD")))) +
  theme_bw() + 
  scale_color_brewer(palette="RdYlBu", name="Prevalence") + 
  xlab("Pool size") + ylab("Average tests per sample") + 
  ggtitle("Uncorrelated Data & Correlated Data Sampled by Group (Fraction = 1)") +
  scale_x_continuous(limits=c(1,20), breaks=seq(0,20,2)) + scale_y_continuous(limits=c(0, 1.6),breaks=seq(0,1.6,0.2)) +
  guides(color=guide_legend(title="Proportion of\ntests positive")) +
  guides(linetype=guide_legend(title="Correlation Structure"))
dev.off()
```


# group_frac = 1/2
```{r}
# correlated (sampled w. grouping) vs. uncorrelated

#subset uncorrelated data to contain same obs as correlated data
# allci_uncorr_sub <- allci_uncorr[allci_uncorr$X %in% allci_corr_group1$X,]
# allci_uncorr_sub$corr_type <- "Uncorrelated"
allci_corr_group12$corr_type <- "Correlated"

# Print plot of pool size vs. PPA, panel grid of % samples with Ct > LoD, color by proportion test pos
pdf("plot.ppa.above.colprev.groupfrac12.both.pdf",width=8, height=5)
ggplot() +
  geom_line(allci_corr_group12, mapping = aes(x=pool, y=tp/(tp + fn), color=as.factor(prevalence), linetype = corr_type)) +
  geom_line(allci_uncorr_sub, mapping = aes(x=pool, y=tp/(tp + fn), color=as.factor(prevalence), linetype = corr_type)) +
  facet_wrap(vars(factor(allci_corr_group12$above.llod, labels=c("5% samples Ct>LoD","10% samples Ct>LoD","15% samples Ct>LoD","20% samples Ct>LoD","25% samples Ct>LoD","30% samples Ct>LoD")))) +
  theme_bw() + 
  scale_color_brewer(palette="RdYlBu", name="Prevalence") + 
  xlab("Pool size") + ylab("Expected positive percent agreement") +
  ggtitle("Uncorrelated Data & Correlated Data Sampled by Group (Fraction = 1/2)") +
  scale_x_continuous(limits=c(1,20), breaks=seq(0,20,2)) + scale_y_continuous(limits=c(0.65,1),breaks=seq(0.65,1,.1)) +
  guides(color=guide_legend(title="Proportion of\ntests positive")) + 
  guides(linetype=guide_legend(title="Correlation Structure")) 
dev.off()

# Print plot of pool size vs. PPA, panel grid of proportion test pos, color by % samples with Ct > LoD
pdf("plot.ppa.prev.colabove.groupfrac12.both.pdf",width=8, height=5)
ggplot() + 
  geom_line(allci_corr_group12, mapping = aes(x=pool, y=tp/(tp + fn), color=as.factor(above.llod), linetype = corr_type)) +
  geom_line(allci_uncorr_sub, mapping = aes(x=pool, y=tp/(tp + fn), color=as.factor(above.llod), linetype = corr_type)) +
  facet_wrap(vars(factor(allci_corr_group12$prevalence, labels=c("0.1% Tests positive", "1% Tests positive", "3% Tests positive", "5% Tests positive", "10% Tests positive","15% Tests positive")))) +
  theme_bw() + 
  scale_color_brewer(palette="RdYlBu", name="Prevalence") + 
  xlab("Pool size") + ylab("Expected positive percent agreement") +
  ggtitle("Uncorrelated Data & Correlated Data Sampled by Group (Fraction = 1/2)") +
  scale_x_continuous(limits=c(1,20), breaks=seq(0,20,2)) + scale_y_continuous(limits=c(0.5,1),breaks=seq(0.5,1,.1)) +
  guides(color=guide_legend(title="Proportion\nsamples\nCt > LoD")) + 
  guides(linetype=guide_legend(title="Correlation Structure")) 
dev.off()

# Print plot of pool size vs. average tests/sample, panel grid of %Ct > LoD, color by proportion test pos
pdf("plot.eff.above.colprev.groupfrac12.both.pdf",width=8, height=5)
ggplot() + 
  geom_line(allci_corr_group12, mapping = aes(x=pool, y=tests.per.sample, color=as.factor(prevalence), linetype = corr_type)) +
  geom_line(allci_uncorr_sub, mapping = aes(x=pool, y=tests.per.sample, color=as.factor(prevalence), linetype = corr_type)) +
  facet_wrap(vars(factor(allci_corr_group12$above.llod, labels=c("5% samples Ct>LoD","10% samples Ct>LoD","15% samples Ct>LoD","20% samples Ct>LoD","25% samples Ct>LoD","30% samples Ct>LoD")))) +
  theme_bw() + 
  scale_color_brewer(palette="RdYlBu", name="Prevalence") + 
  xlab("Pool size") + ylab("Average tests per sample") + 
  ggtitle("Uncorrelated Data & Correlated Data Sampled by Group (Fraction = 1/2)") +
  scale_x_continuous(limits=c(1,20), breaks=seq(0,20,2)) + scale_y_continuous(limits=c(0, 1.6),breaks=seq(0,1.6,0.2)) +
  guides(color=guide_legend(title="Proportion of\ntests positive")) +
  guides(linetype=guide_legend(title="Correlation Structure"))
dev.off()
```

# group_frac = 3/4
```{r}
# correlated (sampled w. grouping) vs. uncorrelated

#subset uncorrelated data to contain same obs as correlated data
# allci_uncorr_sub <- allci_uncorr[allci_uncorr$X %in% allci_corr_group1$X,]
# allci_uncorr_sub$corr_type <- "Uncorrelated"
allci_corr_group34$corr_type <- "Correlated"

# Print plot of pool size vs. PPA, panel grid of % samples with Ct > LoD, color by proportion test pos
pdf("plot.ppa.above.colprev.groupfrac34.both.pdf",width=8, height=5)
ggplot() +
  geom_line(allci_corr_group34, mapping = aes(x=pool, y=tp/(tp + fn), color=as.factor(prevalence), linetype = corr_type)) +
  geom_line(allci_uncorr_sub, mapping = aes(x=pool, y=tp/(tp + fn), color=as.factor(prevalence), linetype = corr_type)) +
  facet_wrap(vars(factor(allci_corr_group34$above.llod, labels=c("5% samples Ct>LoD","10% samples Ct>LoD","15% samples Ct>LoD","20% samples Ct>LoD","25% samples Ct>LoD","30% samples Ct>LoD")))) +
  theme_bw() + 
  scale_color_brewer(palette="RdYlBu", name="Prevalence") + 
  xlab("Pool size") + ylab("Expected positive percent agreement") +
  ggtitle("Uncorrelated Data & Correlated Data Sampled by Group (Fraction = 3/4)") +
  scale_x_continuous(limits=c(1,20), breaks=seq(0,20,2)) + scale_y_continuous(limits=c(0.65,1),breaks=seq(0.65,1,.1)) +
  guides(color=guide_legend(title="Proportion of\ntests positive")) + 
  guides(linetype=guide_legend(title="Correlation Structure")) 
dev.off()

# Print plot of pool size vs. PPA, panel grid of proportion test pos, color by % samples with Ct > LoD
pdf("plot.ppa.prev.colabove.groupfrac34.both.pdf",width=8, height=5)
ggplot() + 
  geom_line(allci_corr_group34, mapping = aes(x=pool, y=tp/(tp + fn), color=as.factor(above.llod), linetype = corr_type)) +
  geom_line(allci_uncorr_sub, mapping = aes(x=pool, y=tp/(tp + fn), color=as.factor(above.llod), linetype = corr_type)) +
  facet_wrap(vars(factor(allci_corr_group34$prevalence, labels=c("0.1% Tests positive", "1% Tests positive", "3% Tests positive", "5% Tests positive", "10% Tests positive","15% Tests positive")))) +
  theme_bw() + 
  scale_color_brewer(palette="RdYlBu", name="Prevalence") + 
  xlab("Pool size") + ylab("Expected positive percent agreement") +
  ggtitle("Uncorrelated Data & Correlated Data Sampled by Group (Fraction = 3/4)") +
  scale_x_continuous(limits=c(1,20), breaks=seq(0,20,2)) + scale_y_continuous(limits=c(0.5,1),breaks=seq(0.5,1,.1)) +
  guides(color=guide_legend(title="Proportion\nsamples\nCt > LoD")) + 
  guides(linetype=guide_legend(title="Correlation Structure")) 
dev.off()

# Print plot of pool size vs. average tests/sample, panel grid of %Ct > LoD, color by proportion test pos
pdf("plot.eff.above.colprev.groupfrac34.both.pdf",width=8, height=5)
ggplot() + 
  geom_line(allci_corr_group34, mapping = aes(x=pool, y=tests.per.sample, color=as.factor(prevalence), linetype = corr_type)) +
  geom_line(allci_uncorr_sub, mapping = aes(x=pool, y=tests.per.sample, color=as.factor(prevalence), linetype = corr_type)) +
  facet_wrap(vars(factor(allci_corr_group34$above.llod, labels=c("5% samples Ct>LoD","10% samples Ct>LoD","15% samples Ct>LoD","20% samples Ct>LoD","25% samples Ct>LoD","30% samples Ct>LoD")))) +
  theme_bw() + 
  scale_color_brewer(palette="RdYlBu", name="Prevalence") + 
  xlab("Pool size") + ylab("Average tests per sample") + 
  ggtitle("Uncorrelated Data & Correlated Data Sampled by Group (Fraction = 3/4)") +
  scale_x_continuous(limits=c(1,20), breaks=seq(0,20,2)) + scale_y_continuous(limits=c(0, 1.6),breaks=seq(0,1.6,0.2)) +
  guides(color=guide_legend(title="Proportion of\ntests positive")) +
  guides(linetype=guide_legend(title="Correlation Structure"))
dev.off()
```




```{r}
# ct_dat <- ct_fake_input_corr
# above <- 1
# positives <- 5
# p <- 6
# 
# # Model loop, vary % above each LOD
# # experiment_loop_corr takes entire ct_dat data frame as argument- should have columns Ct and Z
# experiment_loop_corr <- function(above, ct_dat){ 
#   ct_dat$Ct <- ct_dat$Ct + mat2[above,3] # shift the Ct values by specified percent
#   ct_set <- subset(ct_dat, ct_dat$Ct<45) # subset to valid Ct values
#   
#   threshold.ct_index <- as.vector(sapply(sample(ct_set$Z, (n/G), replace = TRUE), function(x) {which(ct_set$Z == x)})) 
#   # sample the indexes by group (i.e. always select all 4 members if a given group is sampled)
#   threshold.ct <- data.frame(Ct = ct_set$Ct[threshold.ct_index], Z = rep(1:(n/G), each = G)) 
#   # replicate Ct values by number of times they appear in sampled indexes (number of times that group was sampled)
# 
#   rbindlist(lapply(1:pool.max, function (p) { # pool size
#     rbindlist(lapply(c(0.001,0.01,0.03,0.05,0.1,0.15), function(prevalence) { # proportion positive tests 
#       rbindlist(lapply(0:p, function(positives) { # number of positives
#         
#         if (positives == 0) {
#           data.frame(limit=lod, pool=p, pos=positives, prevalence=prevalence, 
#                      above.llod = above.lod[above], 
#                      concentration=0, probability = dbinom(positives, p, prevalence), random=0, z.index=0,
#                      call.each.conc=FALSE, tests=1, tn=1,tp=0,fn=0,fp=0)
#         } 
#         else {
#           # dat_index <- as.vector(sapply(sample(threshold.ct$Z, positives * (n/G), replace=T), function(x) {which(threshold.ct$Z == x)}))
#           dat_index <- sapply(sample(threshold.ct$Z, positives * n, replace=T), function(x) {which(threshold.ct$Z == x)})
#           
#           # dat_index <- sapply(sample(threshold.ct$Z, positive_groups * n, replace=T), function(x) {which(threshold.ct$Z == x)})
#           # two step sampling: (1) sample fraction (x) of group (x*G); (2) sample remaining individuals independently (as before) to complete pool size
#           # sample data by group, n experiments
# 
#           dat <- matrix(threshold.ct$Ct[dat_index], nrow = positives)
#           # each column is an experiment, each entry in a row is a sample
#           
#           each.conc = -log2(colSums(2^-dat)/p)+ifelse(dilution.vary.index==1,0,rnorm(mean=0,sd=1.1,n=ncol(dat))) 
#           # sum over each column; negatives dilute the sample, calculate the dilution
#           # sd of 1.1 reflects confidence interval for deviation from perfect log2 dilution in assays
#           
#           data.frame(
#             limit=lod,
#             pool=p,
#             pos=positives,
#             prevalence=prevalence,
#             above.llod=above.lod[above],
#             concentration=each.conc,
#             probability = dbinom(positives, p, prevalence)/n,
#             random=sample(n,n,replace = TRUE)/n, #
#             z.index=ifelse(probit.mode.index<4,probit.z.indices[probit.mode.index],
#                            sample(1:length(z_scores),n,replace=T))) %>%
#             mutate(
#               call.each.conc=probit[1+(z.index-1)*571+each.conc*10-(lod-35.9)*10,2]>random,
#               tests=1 + p * (call.each.conc), # number of tests done (number positive pools + pool size)
#               tn=0,
#               tp=1 * (call.each.conc),
#               fn=1 * (!call.each.conc),
#               fp=0)
#         }
#       }))
#     }))
#   }))
# }
# 
# start_time <- Sys.time()
# allfirst.poolct <- rbindlist(lapply(1:length(above.lod), experiment_loop_corr, ct_dat = ct_fake_input_corr))
# end_time <- Sys.time()
# end_time-start_time
# 
# group_by(allfirst.poolct, pool, prevalence, above.llod, limit) %>% 
#   summarize(pos=weighted.mean(pos, w=probability),
#             total.tests=weighted.mean(tests, w=probability), 
#             tests.per.sample=weighted.mean(tests, w=probability)/mean(pool), # calculate tests per sample
#             tn=weighted.mean(tn, w=probability), 
#             tp=weighted.mean(tp, w=probability), 
#             fn=weighted.mean(fn, w=probability), 
#             fp=weighted.mean(fp, w=probability)) -> apw
# 
# rm(allfirst.poolct)
# 
# all <- as.data.frame(apw)
# rm(apw)
# 
# all2 <- all %>%
#   mutate(ppa=tp/(tp+fn))
# cpi <- as_tibble(BinomCI(all2$ppa*n,n,conf.level=0.95,method="clopper-pearson"))
# allci <- bind_cols(all2,cpi)
# 
# write.csv(allci,"model_output_corr_grouped.csv")
```




